{"metadata":{"name":"Decision Tree Tutorial","user_save_timestamp":"1970-01-01T08:00:00.000Z","auto_save_timestamp":"1970-01-01T08:00:00.000Z","language_info":{"name":"scala","file_extension":"scala","codemirror_mode":"text/x-scala"},"trusted":true,"customLocalRepo":null,"customRepos":null,"customDeps":null,"customImports":null,"customSparkConf":null},"cells":[{"metadata":{},"cell_type":"markdown","source":"## 從檔案讀取資料"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"//從檔案讀取資料\nval rawData = sc.textFile(\"/home/david/churnTrain.csv\")","outputs":[{"name":"stdout","output_type":"stream","text":"rawData: org.apache.spark.rdd.RDD[String] = /home/david/churnTrain.csv MapPartitionsRDD[5247] at textFile at <console>:226\n"},{"metadata":{},"data":{"text/html":"/home/david/churnTrain.csv MapPartitionsRDD[5247] at textFile at &lt;console&gt;:226\n <div class='pull-right text-info'><small>388 milliseconds</small></div>"},"output_type":"execute_result","execution_count":1}]},{"metadata":{},"cell_type":"markdown","source":"## 去除標頭"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"//去除標頭\nval noheader = rawData.mapPartitionsWithIndex((idx, lines) => {\n  if (idx == 0) {\n    lines.drop(1)\n  }\n  lines\n})","outputs":[{"name":"stdout","output_type":"stream","text":"noheader: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[5248] at mapPartitionsWithIndex at <console>:228\n"},{"metadata":{},"data":{"text/html":"MapPartitionsRDD[5248] at mapPartitionsWithIndex at &lt;console&gt;:228\n <div class='pull-right text-info'><small>309 milliseconds</small></div>"},"output_type":"execute_result","execution_count":2}]},{"metadata":{},"cell_type":"markdown","source":"## 依逗號切開資料"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"//依逗號切開資料\nval splitlines = noheader.map(lines => {\n  lines.split(',')\n})","outputs":[{"name":"stdout","output_type":"stream","text":"splitlines: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[5249] at map at <console>:230\n"},{"metadata":{},"data":{"text/html":"MapPartitionsRDD[5249] at map at &lt;console&gt;:230\n <div class='pull-right text-info'><small>232 milliseconds</small></div>"},"output_type":"execute_result","execution_count":3}]},{"metadata":{},"cell_type":"markdown","source":"## 整理資料"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"import org.apache.spark.mllib.regression.LabeledPoint\nimport org.apache.spark.mllib.linalg.Vectors\nval trainData = splitlines.map { col =>      \n  val churn = col(col.size - 1)\n  val intenational = if (col(4) == \"\\\"no\\\"\") 0.toDouble else 1.toDouble\n  val voice = if (col(5) == \"\\\"no\\\"\") 0.toDouble else 1.toDouble\n  val label = if (churn == \"\\\"no\\\"\") 0.toInt else 1.toInt\n  val features = Array(intenational, voice) ++ col.slice(6, col.size - 1).map(_.toDouble)\n  LabeledPoint(label, Vectors.dense(features))\n}\ntrainData.first()","outputs":[{"name":"stdout","output_type":"stream","text":"import org.apache.spark.mllib.regression.LabeledPoint\nimport org.apache.spark.mllib.linalg.Vectors\ntrainData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[5250] at map at <console>:242\nres127: org.apache.spark.mllib.regression.LabeledPoint = (0.0,[0.0,1.0,25.0,265.1,110.0,45.07,197.4,99.0,16.78,244.7,91.0,11.01,10.0,3.0,2.7,1.0])\n"},{"metadata":{},"data":{"text/html":"(0.0,[0.0,1.0,25.0,265.1,110.0,45.07,197.4,99.0,16.78,244.7,91.0,11.01,10.0,3.0,2.7,1.0])\n <div class='pull-right text-info'><small>442 milliseconds</small></div>"},"output_type":"execute_result","execution_count":4}]},{"metadata":{},"cell_type":"markdown","source":"## 建立決策樹"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"import org.apache.spark.mllib.tree.DecisionTree\nimport org.apache.spark.mllib.tree.configuration.Algo\nimport org.apache.spark.mllib.tree.impurity.Entropy\nval maxTreeDepth = 5\nval dtModel = DecisionTree.train(trainData, Algo.Classification, Entropy,maxTreeDepth)","outputs":[{"name":"stdout","output_type":"stream","text":"import org.apache.spark.mllib.tree.DecisionTree\nimport org.apache.spark.mllib.tree.configuration.Algo\nimport org.apache.spark.mllib.tree.impurity.Entropy\nmaxTreeDepth: Int = 5\ndtModel: org.apache.spark.mllib.tree.model.DecisionTreeModel = DecisionTreeModel classifier of depth 5 with 55 nodes\n"},{"metadata":{},"data":{"text/html":"DecisionTreeModel classifier of depth 5 with 55 nodes\n <div class='pull-right text-info'><small>432 milliseconds</small></div>"},"output_type":"execute_result","execution_count":5}]},{"metadata":{},"cell_type":"markdown","source":"## 驗證單筆資料預測結果"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val dataPoint = trainData.first\nval prediction = dtModel.predict(dataPoint.features)","outputs":[{"name":"stdout","output_type":"stream","text":"dataPoint: org.apache.spark.mllib.regression.LabeledPoint = (0.0,[0.0,1.0,25.0,265.1,110.0,45.07,197.4,99.0,16.78,244.7,91.0,11.01,10.0,3.0,2.7,1.0])\nprediction: Double = 0.0\n"},{"metadata":{},"data":{"text/html":"0.0\n <div class='pull-right text-info'><small>320 milliseconds</small></div>"},"output_type":"execute_result","execution_count":6}]},{"metadata":{},"cell_type":"markdown","source":"## 計算Accuracy"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val dtTotalCorrect = trainData.map { point =>\nif (dtModel.predict(point.features) == point.label) 1 else 0\n}.sum\nval dtAccuracy = dtTotalCorrect / trainData.count","outputs":[{"name":"stdout","output_type":"stream","text":"dtTotalCorrect: Double = 3144.0\ndtAccuracy: Double = 0.9432943294329433\n"},{"metadata":{},"data":{"text/html":"0.9432943294329433\n <div class='pull-right text-info'><small>1 second 536 milliseconds</small></div>"},"output_type":"execute_result","execution_count":7}]},{"metadata":{},"cell_type":"markdown","source":"## 計算 Area Under PR 與 AUC"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\nval dtMetrics = Seq(dtModel).map{ model =>\n  val scoreAndLabels = trainData.map { point =>\n    val score = model.predict(point.features)\n    (if (score > 0.5) 1.0 else 0.0, point.label)\n  }\n  val metrics = new BinaryClassificationMetrics(scoreAndLabels)\n  (model.getClass.getSimpleName, metrics.areaUnderPR,metrics.areaUnderROC)\n}\n\n\"For %s: Area Under PR: %f, Area Under AUC %f\".format(dtMetrics(0)._1, dtMetrics(0)._2, dtMetrics(0)._3)","outputs":[{"name":"stdout","output_type":"stream","text":"import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\ndtMetrics: Seq[(String, Double, Double)] = List((DecisionTreeModel,0.81334779440677,0.855933311539719))\nres128: String = For DecisionTreeModel: Area Under PR: 0.813348, Area Under AUC 0.855933\n"},{"metadata":{},"data":{"text/html":"For DecisionTreeModel: Area Under PR: 0.813348, Area Under AUC 0.855933\n <div class='pull-right text-info'><small>494 milliseconds</small></div>"},"output_type":"execute_result","execution_count":8}]},{"metadata":{},"cell_type":"markdown","source":"## 建立預測函式"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"import org.apache.spark.rdd.RDD\nimport org.apache.spark.mllib.tree.impurity.Impurity\nimport org.apache.spark.mllib.tree.impurity.Entropy\nimport org.apache.spark.mllib.tree.impurity.Gini\ndef trainDTWithParams(input: RDD[LabeledPoint], maxDepth: Int, impurity: Impurity) = {\n  DecisionTree.train(input, Algo.Classification, impurity, maxDepth)\n}","outputs":[{"name":"stdout","output_type":"stream","text":"import org.apache.spark.rdd.RDD\nimport org.apache.spark.mllib.tree.impurity.Impurity\nimport org.apache.spark.mllib.tree.impurity.Entropy\nimport org.apache.spark.mllib.tree.impurity.Gini\ntrainDTWithParams: (input: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint], maxDepth: Int, impurity: org.apache.spark.mllib.tree.impurity.Impurity)org.apache.spark.mllib.tree.model.DecisionTreeModel\n"},{"metadata":{},"data":{"text/html":"\n <div class='pull-right text-info'><small>122 milliseconds</small></div>"},"output_type":"execute_result","execution_count":9}]},{"metadata":{},"cell_type":"markdown","source":"## 測試不同深度的效果"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val dtResultsEntropy = Seq(1,2,3,4,5,10,20).map { param =>\n  val model = trainDTWithParams(trainData, param, Entropy)\n  val scoreAndLabels = trainData.map { point =>\n    val score = model.predict(point.features)\n    (if (score > 0.5) 1.0 else 0.0, point.label)\n  }\n    val metrics = new BinaryClassificationMetrics(scoreAndLabels)\n  (s\"$param tree depth\", metrics.areaUnderROC)\n}\ndtResultsEntropy.foreach { case (param, auc) => println(f\"$param,AUC = ${auc * 100}%2.2f%%\") }","outputs":[{"name":"stdout","output_type":"stream","text":"1 tree depth,AUC = 61.48%\n2 tree depth,AUC = 72.64%\n3 tree depth,AUC = 69.23%\n4 tree depth,AUC = 78.09%\n5 tree depth,AUC = 85.59%\n10 tree depth,AUC = 92.89%\n20 tree depth,AUC = 100.00%\ndtResultsEntropy: Seq[(String, Double)] = List((1 tree depth,0.6148381824125532), (2 tree depth,0.7264127710580799), (3 tree depth,0.6923014056881334), (4 tree depth,0.7809077040427155), (5 tree depth,0.855933311539719), (10 tree depth,0.9289048708728342), (20 tree depth,1.0))\n"},{"metadata":{},"data":{"text/html":"\n <div class='pull-right text-info'><small>2 seconds 524 milliseconds</small></div>"},"output_type":"execute_result","execution_count":10}]},{"metadata":{},"cell_type":"markdown","source":"## 使用Gini Impurity"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val dtResultsEntropy = Seq(1,2,3,4,5,10,20).map { param =>\n  val model = trainDTWithParams(trainData, param, Gini)\n  val scoreAndLabels = trainData.map { point =>\n    val score = model.predict(point.features)\n    (if (score > 0.5) 1.0 else 0.0, point.label)\n  }\n    val metrics = new BinaryClassificationMetrics(scoreAndLabels)\n  (s\"$param tree depth\", metrics.areaUnderROC)\n}\ndtResultsEntropy.foreach { case (param, auc) => println(f\"$param,AUC = ${auc * 100}%2.2f%%\") }","outputs":[{"name":"stdout","output_type":"stream","text":"1 tree depth,AUC = 61.48%\n2 tree depth,AUC = 72.64%\n3 tree depth,AUC = 69.23%\n4 tree depth,AUC = 77.40%\n5 tree depth,AUC = 85.34%\n10 tree depth,AUC = 93.48%\n20 tree depth,AUC = 100.00%\ndtResultsEntropy: Seq[(String, Double)] = List((1 tree depth,0.6148381824125532), (2 tree depth,0.7264127710580799), (3 tree depth,0.6923014056881334), (4 tree depth,0.7740470742072573), (5 tree depth,0.8534237768333879), (10 tree depth,0.9347826086956521), (20 tree depth,1.0))\n"},{"metadata":{},"data":{"text/html":"\n <div class='pull-right text-info'><small>2 seconds 339 milliseconds</small></div>"},"output_type":"execute_result","execution_count":11}]},{"metadata":{},"cell_type":"markdown","source":"## 將資料分為訓練資料集與測試資料集"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val trainTestSplit = trainData.randomSplit(Array(0.6, 0.4), 123)\nval train = trainTestSplit(0)\nval test = trainTestSplit(1)","outputs":[{"name":"stdout","output_type":"stream","text":"trainTestSplit: Array[org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint]] = Array(PartitionwiseSampledRDD[5808] at randomSplit at <console>:245, PartitionwiseSampledRDD[5809] at randomSplit at <console>:245)\ntrain: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = PartitionwiseSampledRDD[5808] at randomSplit at <console>:245\ntest: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = PartitionwiseSampledRDD[5809] at randomSplit at <console>:245\n"},{"metadata":{},"data":{"text/html":"PartitionwiseSampledRDD[5809] at randomSplit at &lt;console&gt;:245\n <div class='pull-right text-info'><small>206 milliseconds</small></div>"},"output_type":"execute_result","execution_count":13}]},{"metadata":{},"cell_type":"markdown","source":"## Cross-Validation"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val dtResultsTrain = Seq(1,2,3,4,5,10,20).map { param =>\n\tval model = trainDTWithParams(train, param, Gini)\n  val dtMetrics = Seq(model).map{ model =>\n    val scoreAndLabels = test.map { point =>\n      val score = model.predict(point.features)\n      (if (score > 0.5) 1.0 else 0.0, point.label)\n    }\n    val metrics = new BinaryClassificationMetrics(scoreAndLabels)\n    (model.getClass.getSimpleName, metrics.areaUnderPR,metrics.areaUnderROC)\n  }\n  dtMetrics\n}\n\ndtResultsTrain.map { mo => (mo(0)._1, mo(0)._2, mo(0)._3) }","outputs":[{"name":"stdout","output_type":"stream","text":"dtResultsTrain: Seq[Seq[(String, Double, Double)]] = List(List((DecisionTreeModel,0.47784313458045485,0.6065949752569472)), List((DecisionTreeModel,0.5494573577086825,0.607791682527598)), List((DecisionTreeModel,0.6794484606182571,0.692895888846593)), List((DecisionTreeModel,0.72761902505717,0.7578226113437381)), List((DecisionTreeModel,0.8031273435851994,0.8353207080319757)), List((DecisionTreeModel,0.7210894926653626,0.8380781309478493)), List((DecisionTreeModel,0.6830573546482825,0.8266344689760182)))\nres131: Seq[(String, Double, Double)] = List((DecisionTreeModel,0.47784313458045485,0.6065949752569472), (DecisionTreeModel,0.5494573577086825,0.607791682527598), (DecisionTreeModel,0.6794484606182571,0.692895888846593), (DecisionTreeModel,0.72761902505717,0.7578226113437381), (Decision..."},{"metadata":{},"data":{"text/html":"<div class=\"container-fluid\"><div><div class=\"col-md-12\"><div>\n    <script data-this=\"{&quot;dataId&quot;:&quot;anon9aad8f0bb8edec5d19103be1c0e97025&quot;,&quot;dataInit&quot;:[{&quot;_1&quot;:&quot;DecisionTreeModel&quot;,&quot;_2&quot;:0.47784313458045485,&quot;_3&quot;:0.6065949752569472},{&quot;_1&quot;:&quot;DecisionTreeModel&quot;,&quot;_2&quot;:0.5494573577086825,&quot;_3&quot;:0.607791682527598},{&quot;_1&quot;:&quot;DecisionTreeModel&quot;,&quot;_2&quot;:0.6794484606182571,&quot;_3&quot;:0.692895888846593},{&quot;_1&quot;:&quot;DecisionTreeModel&quot;,&quot;_2&quot;:0.72761902505717,&quot;_3&quot;:0.7578226113437381},{&quot;_1&quot;:&quot;DecisionTreeModel&quot;,&quot;_2&quot;:0.8031273435851994,&quot;_3&quot;:0.8353207080319757},{&quot;_1&quot;:&quot;DecisionTreeModel&quot;,&quot;_2&quot;:0.7210894926653626,&quot;_3&quot;:0.8380781309478493},{&quot;_1&quot;:&quot;DecisionTreeModel&quot;,&quot;_2&quot;:0.6830573546482825,&quot;_3&quot;:0.8266344689760182}],&quot;genId&quot;:&quot;1724937104&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/tableChart'], \n      function(playground, _magictableChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magictableChart,\n    \"o\": {\"headers\":[\"_1\",\"_2\",\"_3\"],\"nrow\":7,\"shown\":25,\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script></div></div></div></div>\n <div class='pull-right text-info'><small>2 seconds 418 milliseconds</small></div>"},"output_type":"execute_result","execution_count":14}]}],"nbformat":4}